---
title: "Virtual Mutation Data Analysis for the AST 2016 Paper"
output:
  pdf_document:
    keep_tex: true
    highlight: pygments
---

# Installing the Virtual Mutation Package

This code will load in the virtual mutation package from a local directory. I was not able to get it to work with an
installation from Bitbucket because of permission errors. You will need to change the path so that it is correct for
your file system.

```{r, echo=TRUE}
options(scipen=10, width=200)
mypath = "/home/gkapfham/working/research/source/analysis/databases/"
devtools::install_local(paste(mypath, "virtualmutationanalysis", sep=""))
```

# Comparing "Time-Constrained" Original Mutation and Virtual Mutation

## Initialise the System

First, load in the libraries that are used in addition to those with the virtualmutationanalysis package. Note that
right now the virtualmutationanalysis package will automatically load all of the packages that it needs to performs its
various analyses.

```{r, echo=TRUE}
library(virtualmutationanalysis)
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(grid))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(scales))
```

## Visualise the Mutation Scores

Now, plot the graph that shows the mutation scores for the virtual mutation technique and the original mutation method
that can run for the same amount of time as the virtual one.

```{r, echo=TRUE}
time_constrained_data = read_time_constrained_mutation_data_subset()
time_constrained_data_tidy = time_constrained_data %>% transform_time_constrained_data_for_scores()
visualise_mutation_score_time_constrained(time_constrained_data_tidy)
```

Analysis of the results in this graph:

- Much more variability for the time-constrained method than the virtual one
- Greater variability in the Person schema is due to the fact that sometimes the score is zero, other times it is one
- Also, the BankAccount schema sees a lot of variability, with noticeable high and low values

Additional data points to support this analysis:

```{r, echo=TRUE}
time_constrained_data_tidy %>%
  filter(schema %in% c("Person")) %>%
  filter(dbms %in% c("Postgres")) %>%
  filter(score_type %in% c("Time-Constrained")) %>%
  print(n=100)
time_constrained_data_tidy %>%
  filter(schema %in% c("BankAccount")) %>%
  filter(dbms %in% c("HyperSQL")) %>%
  filter(score_type %in% c("Time-Constrained")) %>%
  print(n=100)
```

## Visualise the Total Number of Mutants

```{r, echo=TRUE}
time_constrained_data = read_time_constrained_mutation_data()
time_constrained_data_totals_tidy = time_constrained_data %>%
  transform_time_constrained_data_for_totals()
visualise_mutation_totals_time_constrained(time_constrained_data_totals_tidy)
```

Analysis of the results in this graph:

- The values for the Time-Constrained method are averages across the thirty runs
- There is the greatest disparity in the total number of mutants run for the Postgres DBMS
- Running mutation analysis on the Postgres DBMS only allows 0, 1, 2, or 3 mutants to be run
- For SQLite, it is possible to run all of the mutants for a small number of schemas (e.g., StudentResidence)
- I did several "spot checks" and the values in the graph seem to be correct (e.g., low values for Postgres)

## Evaluating the Correlation Between the Scores

```{r, echo=TRUE}
time_constrained_data = read_time_constrained_mutation_data()
calculate_mutation_score_correlation(time_constrained_data)
```

Analysis of the results in this output:

- The p-value is very low and thus essentially zero. This rules out the hypothesis that the value of $\tau_b$ is equal to
  zero, which would have indicate that there is no correlation between the mutation scores.
- If the correlation has a value of 1 this means that the scores are in perfect agreement.
- If the correlation has a value of -1 this means that the scores are in perfect disagreement.
- The score of $0.49$ indicates that there is a "modest" agreement between the mutation scores.
